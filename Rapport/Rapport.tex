\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{eurosym}
\usepackage[margin=2.5cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{float}
\usepackage{perpage}
\MakePerPage{footnote}

% Fallback for mathbb if not defined
\providecommand{\mathbb}[1]{\mathbf{#1}}

\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{longtable}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Rapport P1RV},
    pdfpagemode=FullScreen,
}
\renewcommand{\contentsname}{Table des matières}

\begin{document}
\begin{titlepage}
    \centering
    \vspace*{2cm}
    
    {\Huge \textbf{Rapport de Projet P1RV}}
    
    \vspace{1.5cm}
    
    {\Large \textbf{Optimisation et Parallélisation du Pricing d'Options Américaines}}\\
    \vspace{0.5cm}
    {\large \textit{Méthode de Monte Carlo Longstaff-Schwartz sur CPU et GPU}}
    
    \vspace{3cm}
    
    \textbf{Auteurs :} \\
    \vspace{0.5cm}
    {\Large Florian BARBE} \\
    {\Large Narjisse EL MANSSOURI}
    
    \vspace{3cm}
    
    \vfill
    
    {\large École Centrale de Nantes} \\
    \vspace{0.2cm}
    {\large Année Universitaire 2025 -- 2026}
    
\end{titlepage}

\newpage
\tableofcontents
\newpage
% \listoffigures
\newpage

\section{Introduction}

Ce rapport présente le travail réalisé durant le premier semestre de la deuxième année de notre cursus ingénieur à Centrale Nantes, dans le cadre de notre projet P1RV. Ce projet s’inscrit dans une démarche d’analyse de performance et de mise en œuvre d’algorithmes numériques avancés, appliqués ici au domaine de la finance quantitative.

Le sujet central du projet porte sur l’évaluation et la comparaison de différentes stratégies de calcul pour le pricing d’options américaines, en s’appuyant sur l’algorithme LSMC (\emph{Least Squares Monte Carlo}), également appelé méthode de Monte Carlo avec régression par moindres carrés ou méthode de Longstaff--Schwartz. Cette approche est aujourd’hui largement utilisée pour la valorisation de produits dérivés complexes lorsque les solutions analytiques fermées ne sont pas disponibles.

La valorisation des options américaines est intrinsèquement plus complexe que celle des options européennes en raison de la possibilité d’un exercice anticipé à tout instant avant la maturité. Cette caractéristique impose la détermination d’une politique d’exercice optimale, rendant inadaptées les méthodes classiques fondées uniquement sur des formules fermées (c'est-à-dire une formule explicite, finie, calculable directement et sans itération). L’algorithme LSMC tente de répondre à cette difficulté en combinant des simulations de Monte Carlo avec des régressions par moindres carrés, permettant d’estimer, à chaque date d’exercice possible, la valeur de continuation associée au maintien de l’option.

Au-delà de l’aspect théorique, ce projet s’inscrit dans une problématique de performance numérique, car les méthodes de Monte Carlo nécessitent la simulation d’un très grand nombre de trajectoires afin de garantir la convergence statistique et la précision des résultats, entraînant des coûts de calcul élevés. Le travail réalisé s'étend donc également à l'évaluation de l’impact de différentes architectures de calcul sur les performances de notre algorithme.

Nous avons donc décidé de décliner notre objectif principal en trois volets complémentaires:
\begin{itemize}
    \item \textbf{Implémentation séquentielle sur CPU} : développement initial d'une version simple en fonctionnement normal sur CPU, dans le but de valider le fonctionnement de l'algorithme. Il servira en point de comparaison de référence pour la suite.
    \item \textbf{Parallélisation sur CPU} : utilisation d’OpenMP afin d’exploiter le parallélisme multi-cœurs du processeur et de réduire, en toute logique, le temps d’exécution des simulations.
    \item \textbf{Implémentation accélérée sur GPU} : recours à la librairie CUDA pour déporter les calculs les plus intensifs, notamment la simulation des trajectoires et certaines opérations de régression, vers une architecture presque complètement parallèle, dans le but de gagner davantage de performances.
\end{itemize}

\newpage
\section{Cadre théorique}

\subsection{Options américaines et problématique de l’exercice anticipé}

Une option américaine confère à son détenteur le droit, mais non l’obligation, d’acheter ou de vendre un actif sous-jacent à un prix fixé à l’avance, appelé \emph{strike}, à tout instant compris entre la date d’émission et la date de maturité. Cette caractéristique la distingue des options européennes, pour lesquelles l’exercice n’est autorisé qu’à maturité.

\begin{table}[H]
\centering
\small
\begin{tabular}{|l|p{5cm}|p{5cm}|}
\hline
\textbf{Caractéristique} & \textbf{Options Américaines} & \textbf{Options Européennes} \\
\hline
\textbf{Moment d'exercice} & À tout moment avant maturité. & Seulement à maturité. \\
\hline
\textbf{Risque d'exercice anticipé} & Oui, particulièrement en présence de dividendes. & Aucun exercice anticipé. \\
\hline
\textbf{Modèle de pricing} & Prime possible liée à la flexibilité d'exercice. & Suit typiquement le modèle Black-Scholes. \\
\hline
\textbf{Parité Put-Call} & Peut ne pas tenir (dû à l'exercice anticipé). & Tient strictement (marché efficient). \\
\hline
\textbf{Sous-jacents courants} & Actions US, ETFs, indices. & Indices européens. \\
\hline
\end{tabular}
\caption{Comparaison entre Options Américaines et Européennes.}
\label{tab:american_vs_european}
\end{table}

La possibilité d’un exercice anticipé introduit une complexité dans le processus de valorisation. En effet, à chaque date d’observation, le détenteur de l’option doit comparer le gain associé à un exercice immédiat avec celui attendu en conservant l’option. Cette décision repose sur l’identification d’une stratégie d’exercice optimal, dépendant à la fois du temps restant jusqu’à maturité et de l’évolution future du prix du sous-jacent.

La valorisation des options américaines s’apparente ainsi à un problème de décision dynamique, pour lequel il est généralement impossible d’obtenir une solution analytique fermée. Cette difficulté motive le recours à des méthodes numériques capables de traiter explicitement l’exercice anticipé.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{images/exercise_boundary.png}
    \caption{La figure illustre la règle de décision d’une option américaine : à chaque instant, la valeur de continuation est comparée au payoff immédiat. La frontière $L^*(t)$ délimite la région dans laquelle il est optimal d’exercer l’option de celle où il est préférable de la conserver. \\
    \textbf{Légende :} L'axe des abscisses représente le prix du sous-jacent $S_t$, l'ordonnée la valeur de l'option. $L^*(t)$ est la frontière d'exercice optimal. $V$ est la valeur de l'option, $V^*$ sa valeur intrinsèque. $LV$ est l'opérateur de Black-Scholes.}
    \label{fig:exercise_boundary}
\end{figure}

\subsection{Modélisation stochastique du sous-jacent}

La valorisation des options américaines par des méthodes de Monte Carlo nécessite un modèle probabiliste décrivant l’évolution du prix du sous-jacent au cours du temps. Dans ce projet, on adopte un cadre classique de finance quantitative fondé sur un modèle stochastique continu\footnote{Défini formellement par un espace probabilisé filtré $(\Omega, \mathcal{F}, (\mathcal{F}_t)_{t \ge 0}, \mathbb{P})$ satisfaisant les conditions habituelles, où l'évolution des prix est modélisée par des processus d'Itô.}, permettant de simuler un grand nombre de trajectoires réalistes du prix de l’actif.

\subsubsection{Mouvement brownien géométrique}

Un \emph{mouvement brownien} (ou processus de Wiener) est un processus stochastique continu $(W_t)_{t \ge 0}$ modélisant une source d’aléa pure, sans mémoire, évoluant dans le temps. Il peut être interprété comme la limite d’une marche aléatoire lorsque le pas de temps tend vers zéro.

Un mouvement brownien standard est caractérisé par les propriétés suivantes :
\begin{itemize}
  \item \textbf{Condition initiale} : $W_0 = 0$.
  \item \textbf{Continuité des trajectoires} : Les trajectoires $t \mapsto W_t$ sont continues presque sûrement.
  \item \textbf{Incréments indépendants} : Pour tout entier $n \ge 1$ et pour tout vecteur de temps $(t_0,\dots,t_n)$ tel que $0 \le t_0 < t_1 < \cdots < t_n$, les variables aléatoires $W_{t_1}-W_{t_0}, \dots, W_{t_n}-W_{t_{n-1}}$ sont indépendantes.
  \item \textbf{Incréments stationnaires} : Pour tout $t \ge 0$ et tout $h > 0$, la variable aléatoire $W_{t+h}-W_t$ a une loi qui dépend uniquement de $h$.
  \item \textbf{Incréments gaussiens centrés} : $W_{t+h}-W_t \sim \mathcal{N}(0,h)$.
\end{itemize}

Les trajectoires d’un mouvement brownien sont continues mais presque sûrement nulle part dérivables, traduisant une évolution extrêmement irrégulière. Ces propriétés impliquent notamment une absence de mémoire du processus ainsi qu’une croissance de l’incertitude proportionnelle au temps.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{images/mouvement_brownien.png}
    \caption{Réalisations de mouvements browniens standards. Les trajectoires sont continues mais presque sûrement nullepart dérivables, ce qui reflète l’absence de régularité locale et la nature purement aléatoire du processus.}
    \label{fig:brownian}
\end{figure}

Pour modéliser l’évolution d’un prix d’actif financier, l’utilisation d’un tel mouvement brownien n’est cependant pas appropriée, notamment parce qu'elle autoriserait des valeurs négatives du prix. On préfère donc une dynamique multiplicative plutôt qu'additive, dans laquelle l’aléa porte sur les rendements plutôt que sur les variations absolues de prix. Cette approche conduit naturellement au \emph{mouvement brownien géométrique}, qui constitue le modèle de référence pour la dynamique du prix d’un sous-jacent $S_t$.

Le mouvement brownien géométrique est défini comme la solution de l’équation différentielle stochastique
\[
\mathrm{d}S_t = \mu S_t\,\mathrm{d}t + \sigma S_t\,\mathrm{d}W_t,
\]
où $\mu$ est le drift\footnote{Tendance déterministe moyenne du cours, représentant le taux de rendement espéré de l'actif.} et $\sigma$ la volatilité.
Cette équation est une équation différentielle stochastique linéaire au sens d’Itô\footnote{Une équation différentielle stochastique (EDS) est dite linéaire au sens d'Itô si les coefficients de dérive et de diffusion sont des fonctions affines de la variable d'état $S_t$.}, issue de l’équation de Black--Scholes\footnote{Voir \cite{Hull} pour une dérivation complète de l'équation aux dérivées partielles de Black-Scholes.}.
Sous ce modèle, le prix $S_t$ suit une loi log-normale\footnote{Une variable aléatoire suit une loi log-normale si son logarithme népérien suit une loi normale. Ceci implique que le prix $S_t$ reste strictement positif.} et admet l’expression explicite (voir le détail de la résolution en \textbf{Annexe \ref{appendix:eds}}) :
\[
S_t = S_0 \exp\left(\left(\mu - \frac{1}{2}\sigma^2\right)t + \sigma W_t\right).
\]

Dans le cadre de ce travail ($q=0$, mesure risque-neutre\footnote{Mesure de probabilité $\mathbb{Q}$ sous laquelle le prix actualisé de tout actif non versant de dividendes est une martingale. Elle est fondamentale pour la valorisation d'actifs contingents (options).}), la dynamique se réduit à :
\[
\mathrm{d}S_t = r S_t\,\mathrm{d}t + \sigma S_t\,\mathrm{d}W_t^{\mathbb{Q}},
\]
et la solution explicite est :
\[
S_t = S_0 \exp\left(\left(r - \frac{1}{2}\sigma^2\right)t + \sigma W_t^{\mathbb{Q}}\right).
\]

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{images/gbm_paths.png}
    \caption{Exemples de trajectoires de Mouvement Brownien Géométrique.}
    \label{fig:gbm_paths}
\end{figure}

\subsubsection{Discrétisation temporelle}

La simulation numérique repose sur une discrétisation exacte de cette solution :
\[
S_{t_{n+1}} = S_{t_n} \exp\left( \left(r - \frac{\sigma^2}{2}\right)\Delta t_n + \sigma \sqrt{\Delta t_n}\, Z_n \right), \quad Z_n \sim \mathcal{N}(0,1).
\]
Cette discrétisation correspond à l’utilisation de la solution exacte du mouvement brownien géométrique et ne souffre donc pas d’erreur de schéma temporel.

\subsection{Algorithme de Longstaff--Schwartz (LSMC)}

L’algorithme de Longstaff--Schwartz, également appelé \emph{Least Squares Monte Carlo (LSMC)}, est une méthode de Monte Carlo spécifiquement conçue pour la valorisation des options américaines. Il permet d’estimer la valeur de continuation à chaque date d’exercice possible à partir des trajectoires simulées.

\subsubsection{Valeur de continuation et problème d’arrêt optimal}

On note $V_{t_n}$ la valeur de l'option à la date $t_n$ et $\Phi(S_{t_n})$ sa valeur d'exercice immédiat.
Le prix de l’option américaine correspond au problème d'arrêt optimal :
\[
V_{t_n} = \max\left(\Phi(S_{t_n}),\, C(t_n,S_{t_n})\right),
\]
où la valeur de continuation $C(t_n,S_{t_n})$ est définie par l'espérance conditionnelle :
\[
C(t_n, S_{t_n}) = \mathbb{E}^{\mathbb{Q}}\left[ e^{-r\Delta t_n}\,V_{t_{n+1}} \mid S_{t_n} \right].
\]

\subsubsection{Régression par moindres carrés}

Dans l’algorithme LSMC, la valeur de continuation est approximée par régression sur une base de fonctions $\{ \psi_k(S_{t_n}) \}$ :
\[
\widehat{C}(t_n, S_{t_n}) \approx \sum_{k=0}^{K_{reg}} a_k \, \psi_k(S_{t_n}).
\]

Le choix de cette base est fondamental pour la qualité de l'approximation. Dans le cadre de ce projet, nous avons implémenté et comparé plusieurs familles de polynômes orthogonaux classiques :

\begin{itemize}
    \item \textbf{Base Canonique (Monomiale)} : Constituée des termes simples $1, X, X^2, \dots$. Bien que naturelle, elle engendre des matrices mal conditionnées pour des degrés élevés ($>3$), ce qui peut dégrader la précision numérique.
    \item \textbf{Polynômes de Laguerre} : Orthogonaux sur $\mathbb{R}^+$ avec le poids $e^{-x}$, ils sont théoriquement adaptés aux variables positives comme les prix d'actifs $S_t$.
    \item \textbf{Polynômes d'Hermite} : Orthogonaux sur $\mathbb{R}$ pour la mesure gaussienne. Ils sont pertinents dans le modèle Black-Scholes où le log-prix est gaussien.
    \item \textbf{Polynômes de Legendre} : Orthogonaux sur un segment fini, ils offrent une bonne stabilité mais nécessitent un redimensionnement des données.
    \item \textbf{Polynômes de Chebyshev} : Reconnus pour minimiser l'erreur d'interpolation (phénomène de Runge), ils contribuent à stabiliser la régression.
\end{itemize}

Les définitions mathématiques précises et les relations de récurrence de ces bases sont détaillées en \textbf{Annexe \ref{appendix:polys}}.

Nous avons analysé l'influence de la nature et du degré (2, 3, voire plus) de ces bases sur la convergence du prix et la stabilité du calcul.

\subsection{Synthèse algorithmique et pseudo-algorithme du LSMC}

L’algorithme repose sur une discrétisation du temps et sur la simulation Monte Carlo d’un grand nombre de trajectoires. Les décisions d’exercice sont déterminées par \emph{induction arrière}.

Le pseudo-code suivant résume de manière synthétique les différentes étapes de la méthode.

\begin{algorithm}
\caption{Pseudo-code de l'algorithme de Longstaff--Schwartz (LSMC)}
\label{alg:lsmc}
\begin{algorithmic}[1]
\STATE Simuler $N_{\text{paths}}$ trajectoires $(S_{t_n}^{(i)})_{n}$.
\STATE Initialiser $V_{t_N}^{(i)} = \Phi(S_{t_N}^{(i)})$.
\FOR{$n = N-1$ \textbf{down to} $1$}
    \STATE $Y^{(i)} = e^{-r \Delta t_n} V_{t_{n+1}}^{(i)}$.
    \STATE Régression $Y^{(i)} \approx \widehat{C}(t_n,S_{t_n}^{(i)})$.
    \FOR{chaque trajectoire $i$}
        \IF{$\Phi(S^{(i)}) \ge \widehat{C}(S^{(i)})$}
            \STATE $V^{(i)} \leftarrow \Phi(S^{(i)})$.
        \ELSE
            \STATE $V^{(i)} \leftarrow Y^{(i)}$.
        \ENDIF
    \ENDFOR
\ENDFOR
\STATE $V_0 = \text{mean}(e^{-r t_1} V_{t_1}^{(i)})$.
\end{algorithmic}
\end{algorithm}

\clearpage
\begin{figure}[H]
    \centering
    \includegraphics[height=0.75\textheight,keepaspectratio]{images/risks-11-00145-g001.png}
    \caption{Illustration schématique de la méthode LSMC : Régression sur les trajectoires In-The-Money.}
    \label{fig:lsmc_diagram_new}
\end{figure}

\clearpage
\begin{figure}[H]
    \centering
    \includegraphics[height=0.75\textheight,keepaspectratio]{images/Distributed-LSMC-algorithm-flow-chart.png}
    \caption{Flux de l'algorithme LSMC : Simulation parallèle vs Régression séquentielle.}
    \label{fig:lsmc_flow}
\end{figure}

\textbf{Synthèse :} La structure du LSMC est intrinsèquement hybride. Si la phase de simulation est un candidat idéal pour le parallélisme massif (qualifié d'\textit{embarrassingly parallel}\footnote{Terme technique standard dans la littérature du calcul haute performance (et la documentation CUDA) désignant des tâches pouvant être exécutées de manière totalement indépendante, sans communication entre elles.}), la phase de backward induction impose une synchronisation globale à chaque pas de temps, limitant le potentiel d'accélération sur GPU (loi d'Amdahl).


\newpage
\section{Travail réalisé : implémentation et méthodologie}

Cette section décrit les choix techniques et méthodologiques retenus pour
l’implémentation de l’algorithme de Longstaff--Schwartz, ainsi que les stratégies
de parallélisation mises en œuvre sur CPU et GPU. L’objectif est double :
assurer la validité numérique des résultats tout en évaluant l’impact des
architectures de calcul sur les performances.

\subsection{Environnement de développement}

L’ensemble du projet a été développé en \texttt{C++}, avec une attention
particulière portée aux performances et à la gestion mémoire. Les principaux
outils et technologies utilisés sont :
\begin{itemize}
    \item compilateur \texttt{g++} compatible \texttt{C++17} ;
    \item bibliothèque \texttt{OpenMP} pour la parallélisation CPU ;
    \item \texttt{CUDA C++} pour l’implémentation GPU ;
    \item générateurs pseudo-aléatoires indépendants par thread ;
    \item système de build basé sur \texttt{CMake}.
\end{itemize}

Les calculs ont été réalisés sur une machine équipée d’un processeur multi-cœurs
et d’un GPU NVIDIA compatible CUDA. Les expériences ont été conduites en
privilégiant la reproductibilité et la stabilité numérique.

\subsection{Implémentation CPU séquentielle}

Une première version séquentielle de l’algorithme LSMC a été implémentée afin de
servir de référence fonctionnelle et de point de comparaison en termes de
performance.

Cette version suit strictement les étapes théoriques :
\begin{itemize}
    \item simulation des trajectoires du sous-jacent selon un mouvement brownien
    géométrique ;
    \item calcul des payoffs à chaque date ;
    \item application de la backward induction ;
    \item estimation de la valeur de continuation par régression polynomiale ;
    \item calcul de la moyenne finale des cashflows actualisés.
\end{itemize}

L’implémentation séquentielle permet de valider la cohérence des résultats
numériques et de mesurer le coût de calcul intrinsèque de l’algorithme avant
toute parallélisation.

\subsection{Parallélisation CPU avec OpenMP}

La version parallèle CPU repose sur l’observation que la majorité des calculs
dans l’algorithme LSMC sont indépendants par trajectoire. Cette propriété est
exploitée à l’aide d’OpenMP.

Les sections parallélisées sont notamment :
\begin{itemize}
    \item la génération des trajectoires du sous-jacent ;
    \item le calcul des payoffs ;
    \item l’accumulation des termes des équations normales pour la régression ;
    \item la mise à jour des cashflows lors de la backward induction ;
    \item le calcul de la moyenne finale.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{images/openmp_fork_join.png}
    \caption{Illustration du modèle d'exécution Fork-Join utilisé par OpenMP (Source : Fork-Join model for OpenMP parallelisation).}
    \label{fig:openmp_fork_join}
\end{figure}

Les réductions OpenMP sont utilisées pour agréger efficacement les contributions
des différentes trajectoires, tout en garantissant l’absence de conditions de
course\footnote{Une \emph{race condition} (condition de course) survient lorsque le résultat d'un programme dépend de l'ordre d'exécution imprévisible de threads accédant simultanément à des données partagées en écriture.}. Le schéma \texttt{schedule(static)} est privilégié afin d’assurer une
répartition homogène de la charge de travail et un bon comportement mémoire.

Cette parallélisation permet d’exploiter efficacement les cœurs du processeur,
mais reste limitée par la bande passante mémoire et la nature statistique de
l’algorithme.

\subsection{Accélération GPU avec CUDA}

Une version accélérée sur GPU a été développée afin d’exploiter le parallélisme
massif offert par les architectures CUDA, une approche explorée dans des travaux similaires \cite{Oger, Croain}. Le GPU est particulièrement adapté à
la simulation Monte Carlo, chaque trajectoire pouvant être associée à un thread
indépendant.

Les principales étapes déportées sur le GPU sont :
\begin{itemize}
    \item la simulation des trajectoires du mouvement brownien géométrique ;
    \item le calcul des payoffs ;
    \item certaines phases de réduction nécessaires à la régression.
\end{itemize}

La backward induction impose cependant une dépendance temporelle forte entre les
dates successives, ce qui limite la parallélisation complète de l’algorithme.
L’approche retenue consiste donc à paralléliser intensivement les calculs
spatiaux (trajectoires) tout en conservant une synchronisation globale entre les
dates.

Une attention particulière est portée à l’organisation mémoire des données afin
de garantir des accès coalescents\footnote{L'accès coalescent désigne le regroupement par le matériel de plusieurs requêtes mémoire provenant de threads voisins en une seule transaction physique, optimisant ainsi l'utilisation de la bande passante.} et de limiter les transferts entre l’hôte
(CPU) et le périphérique (GPU).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{images/gpu_memory_architecture.png}
    \caption{Découpage logique de la mémoire et des threads d'un GPU (Architecture CUDA) \cite{Benguigui}.}
    \label{fig:gpu_memory}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.2\textwidth]{images/ada_sm_architecture.png}
    \caption{Architecture d'un Streaming Multiprocessor (SM) Ada Lovelace. Chaque SM contient 4 partitions avec des unités FP32/INT32, des Tensor Cores de 4ème génération, 128 Ko de cache L1/mémoire partagée, et un RT Core de 3ème génération.}
    \label{fig:ada_sm}
\end{figure}

Un paramètre clé de l'optimisation CUDA est la taille des blocs de threads. En CUDA, les threads sont organisés en blocs, et plusieurs blocs sont exécutés sur un même SM. La taille de bloc (nombre de threads par bloc) peut être ajustée par multiples de 32 (taille d'un warp) jusqu'à un maximum de 1024 threads. Ce paramètre influence directement l'occupation des SMs et donc les performances globales. L'impact de ce paramètre sera analysé dans la Section~\ref{sec:gpu_block_benchmark}.

Cette implémentation permet d’évaluer concrètement les gains de performance
apportés par le GPU et de mettre en évidence les limites structurelles du LSMC
dans un contexte massivement parallèle.

\subsection{Méthodes de Différences Finies (FDM) pour comparaison}

Afin de valider nos résultats Monte Carlo et de disposer d'un point de comparaison déterministe performant, nous avons également implémenté des solveurs basés sur les différences finies (FDM) pour l'équation de Black-Scholes-Merton (PDE) \cite{Hull}. Bien que ces méthodes soient limitées en dimension (difficiles à étendre au-delà de 2 ou 3 sous-jacents), elles sont extrêmement efficaces pour les options vanilles\footnote{Les options vanilles désignent les options standard (Call et Put) ayant des caractéristiques classiques (prix d'exercice, date d'échéance) et ne présentant pas de clauses exotiques (barrières, asiatiques, lookback, etc.).} et américaines sur un seul sous-jacent.

Trois schémas numériques ont été implémentés dans le fichier \texttt{fdm.cpp} :
\begin{itemize}
    \item Le schéma de \textbf{Runge-Kutta 4 (RK4)} a été choisi comme méthode de référence ("baseline") pour sa haute précision ($O(\Delta t^4)$). Bien que plus coûteux en calcul que les méthodes d'Euler, il fournit une valeur quasi-exacte pour valider les résultats Monte Carlo.
    \item \textbf{Euler Implicite} : Schéma inconditionnellement stable, nécessitant la résolution d'un système linéaire tridiagonal à chaque pas de temps (algorithme de Thomas\footnote{L'algorithme de Thomas, également appelé TDMA (TriDiagonal Matrix Algorithm), est une forme simplifiée de l'élimination de Gauss optimisée pour les systèmes tridiagonaux. Sa complexité est (n)$ contre (n^3)$ pour l'élimination de Gauss générale.}).
    \item \textbf{Euler Explicite} : Schéma simple et rapide, mais conditionnellement stable (nécessite un pas de temps suffisamment petit pour éviter les instabilités numériques).
\end{itemize}

Ces méthodes nous ont servi de "vérité terrain" pour vérifier la convergence de nos prix LSMC.

\subsection{Structure du code et organisation des fichiers}

Le projet est organisé de manière modulaire pour séparer les responsabilités (modélisation, calcul, utilitaires). Voici une description de l'arborescence :

\begin{itemize}
    \item \texttt{src/} (dossier racine \texttt{P1RV\_CUDA/}) :
    \begin{itemize}
        \item \texttt{lsmc.cu} / \texttt{lsmc.cpp} : Cœur de l'algorithme Longstaff-Schwartz. La version \texttt{.cu} contient les kernels CUDA pour le GPU.
        \item \texttt{gbm.cu} : Simulation du Mouvement Brownien Géométrique.
        \item \texttt{fdm.cpp} : Implémentation des méthodes de différences finies (solvers PDE).
        \item \texttt{main.cu} : Point d'entrée, gestion des arguments et lancement des benchmarks.
    \end{itemize}
    \item \texttt{Utils/} :
    \begin{itemize}
        \item \texttt{csv\_writer.hpp} : Utilitaires pour l'export des résultats.
        \item Scripts Python : Pour l'interface utilisateur et la visualisation.
    \end{itemize}
\end{itemize}



\newpage
\section{Résultats et analyse des performances}

\subsection{Configuration matérielle}

Tous les benchmarks présentés dans cette section ont été réalisés sur une machine équipée d'un processeur \textbf{Intel® Core™ i7-13620H} (13ème génération) et d'une carte graphique \textbf{NVIDIA GeForce RTX 4060}. Cette dernière, basée sur l'architecture Ada Lovelace, dispose de \textbf{3072 cœurs CUDA} et de \textbf{8 Go de mémoire GDDR6}, offrant une puissance de calcul théorique adaptée aux simulations massivement parallèles.

\begin{table}[H]
\centering
\small
\begin{tabular}{|l|c|}
\hline
\textbf{Propriété} & \textbf{Valeur} \\
\hline
Architecture & Ada Lovelace \\
Compute Capability & 8.9 \\
Mémoire totale & 8 Go GDDR6 \\
Driver CUDA & 581.80 \\
\hline
Max threads par bloc & 1024 \\
Max threads par SM & 1536 \\
Taille de warp & 32 \\
Max warps par SM & 48 \\
Max blocs par SM & 16 \\
\hline
\end{tabular}
\caption{Spécifications techniques du GPU RTX 4060 utilisé pour les benchmarks.}
\label{tab:gpu_specs}
\end{table}

Cette section présente les résultats obtenus lors de l’exécution de l’algorithme
de Longstaff--Schwartz selon les différentes architectures étudiées : CPU
séquentiel, CPU parallélisé avec OpenMP et GPU via CUDA.  
L’analyse porte à la fois sur la validité numérique des résultats et sur les
performances de calcul observées.

\subsection{Première approche : comparaison des méthodes de parallélisme}

Les performances ont été évaluées sur un ensemble de simulations Monte Carlo
pour une option de type put américain. Nous avons comparé les temps d'exécution et la précision des prix obtenus par nos trois implémentations (CPU Séquentiel, OpenMP, GPU CUDA) ainsi que par les méthodes de différences finies.

Les résultats ci-dessous ont été obtenus sur une machine équipée d'un GPU NVIDIA.

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|r|r|}
\hline
\textbf{Mode} & \textbf{Pas ($N$)} & \textbf{Trajectoires ($M$)} & \textbf{Prix (\euro)} & \textbf{Temps (ms)} & \textbf{Écart / FDM} \\
\hline
FDM Implicite & 1000 & - & 6.067 & 0.67 & Ref \\
FDM Explicite & 1000 & - & 6.079 & 60.18 & +0.012 \\
FDM RK4 & 1000 & - & 6.079 & 231.88 & +0.012 \\
\hline
CPU Séquentiel & 50 & 100,000 & 6.057 & 559.91 & -0.010 \\
OpenMP & 50 & 100,000 & 6.057 & 540.23 & -0.010 \\
\textbf{GPU CUDA} & 50 & 100,000 & 6.070 & \textbf{41.96} & +0.003 \\
\hline
CPU Séquentiel & 50 & 1,000,000 & 6.059 & 6914.19 & -0.008 \\
OpenMP & 50 & 1,000,000 & 6.059 & 6562.99 & -0.008 \\
\textbf{GPU CUDA} & 50 & 1,000,000 & 6.047 & \textbf{455.63} & -0.020 \\
\hline
CPU Séquentiel & 50 & 5,000,000 & 6.057 & 35352.25 & -0.010 \\
\hline
\end{tabular}
\caption{Comparaison des temps de calcul et précision pour un Put Américain ($S_0=100, K=100, r=0.05, \sigma=0.2, T=1$). (Matériel : i7-13620H + RTX 4060)}
\label{tab:results}
\end{table}

\paragraph{Analyse des résultats :}
\begin{itemize}
    \item \textbf{Précision} : Tous les modes LSMC convergent vers un prix très proche de la référence FDM (~6.067). Les écarts observés sont de l'ordre du centime, ce qui est acceptable pour une méthode de Monte Carlo avec ces paramètres.
    \item \textbf{Performance GPU} : Le GPU démontre une accélération spectaculaire. Pour 1 million de trajectoires, le calcul prend environ \textbf{455 ms} sur GPU contre près de \textbf{7 secondes} (6914 ms) sur CPU séquentiel, soit un facteur d'accélération (speedup) d'environ $\times 15$.
    \item \textbf{Comparaison FDM} : Les méthodes de différences finies (surtout l'implicite) sont extrêmement rapides (< 1ms) pour ce problème 1D. Cela confirme que pour des options simples, les PDE restent supérieures. Cependant, l'intérêt du LSMC (et donc de notre implémentation GPU) réside dans sa capacité à traiter des problèmes de plus haute dimension où les méthodes de grille échouent.
\end{itemize}

\subsection{Pour aller plus loin : analyse de l'impact de la base de régression}

Les benchmarks réalisés ("boosted", voir tableau~\ref{tab:boosted}) révèlent que l'augmentation du degré de la base est bénéfique. La base Cubique permet d'atteindre un prix de $\approx 6.06$, nettement plus proche de la référence théorique ($\approx 6.08$) que les bases quadratiques/monomiales ($\approx 5.58$ dans cette configuration CPU non-optimisée). 

Cette amélioration de précision justifie le léger surcoût calculatoire lié à la résolution de systèmes linéaires $4 \times 4$, désormais gérée par notre solveur de Gauss générique sur GPU.

\begin{table}[H]
\centering
\scriptsize
\begin{tabular}{|l|l|c|r|r|r|}
\hline
\textbf{Base} & \textbf{Architecture} & \textbf{Trajectoires} & \textbf{Prix (\euro)} & \textbf{Temps (ms)} & \textbf{Throughput (ops/s)} \\
\hline
\multicolumn{6}{|c|}{\textbf{N = 100,000}} \\
\hline
Monomiale & CPU Séquentiel & 100k & 5.586 & 261.96 & 19.1 M \\
Monomiale & CPU OpenMP & 100k & 5.586 & 274.97 & 18.2 M \\
Monomiale & GPU & 100k & 6.070 & 45.46 & 109.9 M \\
\hline
Hermite & CPU Séquentiel & 100k & 5.586 & 265.94 & 18.8 M \\
Hermite & CPU OpenMP & 100k & 5.586 & 266.81 & 18.7 M \\
Hermite & GPU & 100k & 6.070 & 43.40 & 115.2 M \\
\hline
Laguerre & CPU Séquentiel & 100k & 5.586 & 268.81 & 18.6 M \\
Laguerre & CPU OpenMP & 100k & 5.586 & 265.83 & 18.8 M \\
Laguerre & GPU & 100k & 6.070 & 35.44 & 141.1 M \\
\hline
Chebyshev & CPU Séquentiel & 100k & 5.586 & 263.63 & 18.9 M \\
Chebyshev & CPU OpenMP & 100k & 5.586 & 265.64 & 18.8 M \\
Chebyshev & GPU & 100k & 6.070 & 41.66 & 120.0 M \\
\hline
Cubique & CPU Séquentiel & 100k & 5.586 & 266.56 & 18.7 M \\
Cubique & CPU OpenMP & 100k & 5.586 & 265.21 & 18.8 M \\
Cubique & GPU & 100k & 6.086 & 38.66 & 129.3 M \\
\hline
\multicolumn{6}{|c|}{\textbf{N = 1,000,000}} \\
\hline
Monomiale & CPU Séquentiel & 1M & 5.565 & 2653.88 & 18.8 M \\
Monomiale & CPU OpenMP & 1M & 5.565 & 2688.26 & 18.6 M \\
Monomiale & GPU & 1M & 6.047 & 334.53 & 149.5 M \\
\hline
Hermite & CPU Séquentiel & 1M & 5.565 & 2672.32 & 18.7 M \\
Hermite & CPU OpenMP & 1M & 5.565 & 2704.67 & 18.5 M \\
Hermite & GPU & 1M & 6.047 & 594.25 & 84.1 M \\
\hline
Laguerre & CPU Séquentiel & 1M & 5.565 & 2710.66 & 18.4 M \\
Laguerre & CPU OpenMP & 1M & 5.565 & 2841.14 & 17.6 M \\
Laguerre & GPU & 1M & 6.047 & 649.80 & 76.9 M \\
\hline
Chebyshev & CPU Séquentiel & 1M & 5.565 & 2633.49 & 18.9 M \\
Chebyshev & CPU OpenMP & 1M & 5.565 & 2638.32 & 18.9 M \\
Chebyshev & GPU & 1M & 6.047 & 626.32 & 79.8 M \\
\hline
Cubique & CPU Séquentiel & 1M & 5.565 & 2677.14 & 18.7 M \\
Cubique & CPU OpenMP & 1M & 5.565 & 2628.52 & 19.0 M \\
Cubique & GPU & 1M & 6.063 & 687.69 & 72.7 M \\
\hline
\end{tabular}
\caption{Benchmarks "Boosted" complets : Impact du choix de la base et de l'architecture. (Matériel : i7-13620H + RTX 4060)}
\label{tab:boosted}
\end{table}

Les temps mesurés confirment l'efficacité de l'approche massivement parallèle pour la phase de simulation. Le goulot d'étranglement restant sur GPU est la régression séquentielle à chaque pas de temps.

Une expérimentation complémentaire a été menée pour tenter d'éliminer totalement les synchronisations CPU durant la phase de régression (implémentation \textbf{Parallélisation Complète de la Régression sur GPU} ou "Full GPU"). Le tableau~\ref{tab:perf_resident} présente les résultats obtenus.

\begin{table}[H]
\centering
\small
\begin{tabular}{|l|l|c|r|r|r|r|}
\hline
\textbf{Base} & \textbf{Architecture} & \textbf{Traj.} & \textbf{Prix (\euro)} & \textbf{Temps (ms)} & \textbf{Ops/s} & \textbf{Speedup vs GPU Std} \\
\hline
\multicolumn{7}{c}{\textbf{N = 100 000}} \\
\hline
Monomiale & GPU Full & 100k & 6.085 & 51.55 & 1.9 M & 0.88$\times$ \\
Hermite & GPU Full & 100k & 6.085 & 86.05 & 1.2 M & 0.50$\times$ \\
Laguerre & GPU Full & 100k & 6.085 & 93.10 & 1.1 M & 0.38$\times$ \\
Chebyshev & GPU Full & 100k & 3.812 & 102.95 & 1.0 M & 0.40$\times$ \\
\hline
\end{tabular}
\caption{Comparaison de performance : Nouveau Solveur GPU "Full" vs Standard (N=100k)}
\label{tab:perf_resident}
\end{table}

Les résultats présentés dans le tableau~\ref{tab:perf_resident} montrent que l’approche dite \emph{Full GPU}, visant à
déporter l’intégralité de la phase de régression sur le GPU, conduit à des temps d’exécution
significativement plus élevés que l’implémentation GPU standard. Ce comportement, a priori
contre-intuitif, s’explique par plusieurs facteurs structurels liés à la nature du calcul et à
l’architecture GPU.

Tout d’abord, la phase de régression repose sur des opérations de réduction globale
(construction des matrices normales, calcul des produits scalaires, résolution de systèmes
linéaires de petite taille) qui présentent un parallélisme intrinsèquement limité. Pour des
tailles de matrices faibles (typiquement $3 \times 3$ ou $4 \times 4$), le coût de lancement
des kernels, les synchronisations entre blocs et la gestion de la mémoire partagée deviennent
prépondérants face au coût arithmétique réel, ce qui dégrade fortement les performances.

De plus, la suppression des normalisations dynamiques (Min/Max) dans certaines bases, bien
qu’elle permette d’éliminer des synchronisations coûteuses, peut engendrer des problèmes de
conditionnement numérique et de stabilité, limitant les gains théoriques attendus. Le GPU se
révèle ainsi particulièrement efficace pour des calculs massivement parallèles et
compute-bound, mais moins adapté à des opérations séquentielles fines et faiblement
dimensionnées comme la résolution répétée de petits systèmes linéaires.

Enfin, cette implémentation \emph{Full GPU} n’a pas fait l’objet d’optimisations approfondies
(kernel fusion, utilisation systématique de bibliothèques spécialisées telles que cuBLAS ou
CUB, restructuration mémoire avancée). Compte tenu des contraintes de temps du projet, il n’a
pas été possible d’explorer plus en détail ces pistes d’optimisation, l’objectif principal
restant l’analyse comparative des architectures CPU, OpenMP et GPU standard dans le cadre du
LSMC.

Ces résultats restent néanmoins instructifs, car ils mettent en évidence les limites pratiques
d’une approche naïvement «~tout GPU~» et soulignent l’intérêt d’architectures hybrides,
dans lesquelles le GPU est réservé aux phases massivement parallèles tandis que certaines
opérations restent plus efficacement traitées sur CPU.

\subsection{Validation numérique}

Avant toute analyse de performance, la cohérence numérique des différentes
implémentations a été vérifiée.  
Les prix obtenus avec :
\begin{itemize}
    \item l’implémentation CPU séquentielle,
    \item l’implémentation CPU OpenMP,
    \item l’implémentation GPU CUDA,
\end{itemize}
sont compatibles entre eux à l’intérieur des intervalles d’erreur statistique
attendus pour une méthode de Monte Carlo.

Lorsque le nombre de trajectoires augmente, la variance de l’estimateur décroît
conformément au taux théorique $\mathcal{O}(1/\sqrt{N_{\text{paths}}})$, ce qui
confirme la bonne implémentation de l’algorithme LSMC sur les trois architectures.

\subsubsection{Analyse de la convergence}

Les résultats présentés en figure~\ref{fig:degree_convergence_full} montrent l'évolution de l'erreur relative par rapport au prix RK4 de référence. Cette dynamique peut être mise en perspective avec la Figure~\ref{fig:basis_comparison} (issue de \cite{Benguigui}) qui illustre les attentes théoriques de convergence. Contrairement à l'intuition théorique qui suggère une amélioration monotone, les courbes observées ne présentent pas une décroissance régulière. Plusieurs facteurs peuvent expliquer ce comportement mitigé et "non concluant" sur ce cas test spécifique :

\begin{itemize}
    \item \textbf{Phénomène de Runge} : L'utilisation de bases polynomiales de degré élevé sur des points non uniformément répartis (les trajectoires stochastiques) peut induire de fortes oscillations aux bords du domaine (valeurs extrêmes de $S_t$), dégradant la qualité globale de la régression \cite{Benguigui}. Cependant, les degrés utilisés ici allant jusqu'à 10, ce phénomène reste modéré pour expliquer à lui seul les variations observées.
    \item \textbf{Conditionnement de la matrice} : Pour des degrés élevés ($d > 5$), la matrice de Gram $A^T A$ devient mal conditionnée, en particulier pour la base Monomiale, ce qui amplifie les erreurs numériques lors de la résolution du système linéaire. Bien que les bases orthogonales (Laguerre, Hermite) soient censées atténuer ce problème, le bruit de Monte Carlo semble ici dominer les gains théoriques.
    \item \textbf{Compromis Biais-Variance} : Augmenter le degré réduit le biais de modélisation (capacité à fitter la "vraie" fonction de continuation) mais augmente la variance de l'estimateur, car le modèle capture le bruit statistique des trajectoires (sur-apprentissage).
\end{itemize}

Il serait également pertinent de comparer ces résultats avec des schémas d'Euler explicite ou implicite, la méthode RK4 pouvant présenter des instabilités dans certains régimes stochastiques.

\subsection{Performances CPU séquentiel}

L’implémentation séquentielle sert de référence de performance.  
Le temps d’exécution croît linéairement avec le nombre de trajectoires simulées,
ce qui est cohérent avec la complexité algorithmique du LSMC :
\[
\mathcal{O}(N_{\text{paths}} \times N_{\text{steps}}).
\]

Cette version met en évidence le caractère fortement coûteux des méthodes de
Monte Carlo lorsque la précision recherchée impose un grand nombre de trajectoires.
Elle justifie pleinement le recours à des techniques de parallélisation.

Les figures ci-dessous illustrent la validation empirique de la complexité linéaire de l'implémentation séquentielle.

\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/linearity_paths.png}
        \caption{Temps vs $N_{paths}$ (CPU Séquentiel)}
        \label{fig:linearity_paths}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/linearity_steps.png}
        \caption{Temps vs $N_{steps}$ (CPU Séquentiel)}
        \label{fig:linearity_steps}
    \end{minipage}
\end{figure}

L'alignement quasi-parfait des points mesurés avec la régression linéaire confirme que l'implémentation respecte la complexité théorique sans overhead significatif cachés.

\subsection{Accélération par parallélisation CPU avec OpenMP}

La version OpenMP exploite le parallélisme multi-cœurs du processeur.  
Les gains observés sont significatifs pour les phases suivantes :
\begin{itemize}
    \item simulation des trajectoires du sous-jacent ;
    \item calcul des payoffs ;
    \item accumulation des équations normales pour la régression ;
    \item mise à jour des cashflows.
\end{itemize}

Les résultats de benchmark avec 4 threads OpenMP confirment une amélioration des temps de calcul, tout en conservant une complexité linéaire globale (voir figures ci-dessous).

\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/linearity_paths_omp.png}
        \caption{Temps vs $N_{paths}$ (OpenMP 4 threads)}
        \label{fig:linearity_paths_omp}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/linearity_steps_omp.png}
        \caption{Temps vs $N_{steps}$ (OpenMP 4 threads)}
        \label{fig:linearity_steps_omp}
    \end{minipage}
\end{figure}

Le facteur d’accélération obtenu est inférieur au nombre de cœurs disponibles,
ce qui s’explique par :
\begin{itemize}
    \item la bande passante mémoire limitée ;
    \item les accès concurrents aux structures de données partagées ;
    \item la présence de phases séquentielles incompressibles (notamment la
    progression temporelle de la backward induction).
\end{itemize}

Néanmoins, OpenMP permet une réduction notable du temps de calcul, tout en conservant une implémentation relatively simple et portable.

\textbf{Synthèse :} Le parallélisme OpenMP est efficace pour les phases \emph{compute-bound} (simulations) mais sature rapidement la bande passante mémoire lors des opérations vectorielles massives, plafonnant l'accélération bien en deçà du nombre de cœurs physiques.

\subsubsection{Analyse du passage à l'échelle selon la taille du problème}

La figure~\ref{fig:openmp_scaling_mosaic} illustre l'évolution du temps d'exécution en fonction du nombre de cœurs pour différentes tailles de problème. Pour de petits nombres de trajectoires (N=1000), le parallélisme n'apporte que peu de bénéfices car le temps de calcul est dominé par les synchronisations et le lancement des threads. En revanche, lorsque le problème grandit (N=100\,000 ou N=1\,000\,000), l'accélération devient très significative, bien qu'elle plafonne rapidement au-delà de 4-6 cœurs en raison de la saturation de la bande passante mémoire.

\begin{figure}[H]
    \centering
    \begin{minipage}{0.32\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/openmp_scaling_1000.png}
        \caption*{N=1\,000}
    \end{minipage}
    \hfill
    \begin{minipage}{0.32\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/openmp_scaling_10000.png}
        \caption*{N=10\,000}
    \end{minipage}
    \hfill
    \begin{minipage}{0.32\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/openmp_scaling_100000.png}
        \caption*{N=100\,000}
    \end{minipage}
    \\[1em]
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/openmp_scaling_1000000.png}
        \caption*{N=1\,000\,000}
    \end{minipage}
    \caption{Passage à l'échelle OpenMP selon la taille du problème (moyenne lissée sur 10 exécutions, min/max exclus). L'accélération est négligeable pour les petits problèmes mais devient significative pour N$\geq$100\,000, avant de plafonner à cause de la bande passante mémoire.}
    \label{fig:openmp_scaling_mosaic}
\end{figure}

\subsection{Accélération GPU avec CUDA}

L’implémentation GPU avec CUDA a mis en évidence \cite{Benguigui} un contraste marqué entre les
différentes phases de l’algorithme. La simulation des trajectoires et le calcul
des payoffs bénéficient pleinement du parallélisme massif, avec des accélérations
importantes lorsque le nombre de trajectoires augmente.

Les résultats expérimentaux (voir Figures ci-dessous) montrent un gain de performance croissant avec la
taille du problème, atteignant des facteurs d’accélération supérieurs à $30$
pour de grands nombres de trajectoires.

\begin{figure}[H]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/linearity_paths_gpu.png}
        \caption{Temps vs $N_{paths}$ (GPU CUDA)}
        \label{fig:linearity_paths_gpu}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/linearity_steps_gpu.png}
        \caption{Temps vs $N_{steps}$ (GPU CUDA)}
        \label{fig:linearity_steps_gpu}
    \end{minipage}
\end{figure}





En revanche, la backward induction impose une dépendance temporelle forte entre les dates successives.
Cette contrainte limite la parallélisation complète de l'algorithme et réduit le gain théorique maximal.
Les performances dépendent notamment :
\begin{itemize}
    \item du nombre de trajectoires simulées ;
    \item de l'occupation effective du GPU ;
    \item de l'efficacité des réductions parallèles ;
    \item de la limitation des transferts mémoire CPU-GPU.
\end{itemize}

\textbf{Synthèse :} Le GPU excelle sur le parallélisme de données (trajectoires), offrant des speedups d'un ordre
de grandeur, mais l'accélération globale reste structurellement bornée par la nature séquentielle temporelle
de l'algorithme (loi d'Amdahl appliquée à la backward induction).

Par ailleurs, une légère différence entre les prix CPU et GPU a été observée.
Elle s’explique par la nature statistique de la méthode de Monte Carlo, les
différences de générateurs pseudo-aléatoires et les effets d’arrondis en
arithmétique flottante. Ces écarts restent toutefois compatibles avec la variance
attendue de l’estimateur.

En ce qui concerne la stabilité des temps de calcul, on observe une variance plus élevée sur GPU que sur CPU.
Ceci s'explique par plusieurs facteurs intrinsèques au fonctionnement d'un GPU dans un environnement non temps-réel :
\begin{itemize}
    \item \textbf{Nature asynchrone :} Les lancements de kernels et les transferts mémoire impliquent une interaction complexe avec le driver, soumise à des latences variables.
    \item \textbf{Gestion dynamique des fréquences :} Le mécanisme de "boost clock" ajuste la fréquence du GPU en temps réel selon la charge et la température, introduisant des fluctuations de performance sur des exécutions courtes.
    \item \textbf{Ressource partagée :} Le GPU étant également sollicité par le système d'affichage (WDDM sous Windows), des micro-interruptions peuvent survenir, contrairement aux threads CPU qui peuvent être plus isolés.
\end{itemize}

Nous avons également évalué l'impact de la taille des blocs de threads sur les performances GPU :

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{images/gpu_block_size_scaling.png}
    \caption{Impact de la taille des blocs GPU sur le temps d'exécution (N=1\,000\,000 trajectoires, 50 pas). Moyenne lissée sur 10 exécutions (min/max exclus).}
    \label{fig:gpu_block_size}
\end{figure}

Les résultats montrent une différence notable entre la plus petite taille (32 threads, soit un seul warp) et les tailles supérieures. Au-delà de 64 threads par bloc, les performances sont relativement stables, suggérant que la taille de 256 threads (valeur par défaut) représente un bon compromis.
\label{sec:gpu_block_benchmark}

\subsection{Comparaison globale des architectures}

De manière synthétique :
\begin{itemize}
    \item le CPU séquentiel fournit une référence simple mais peu performante ;
    \item OpenMP permet un gain modéré, limité par la bande passante mémoire ;
    \item CUDA offre les meilleures performances pour les grandes tailles de
    problèmes, en particulier lorsque le nombre de trajectoires est très élevé.
\end{itemize}

Le GPU s'avère donc particulièrement adapté aux méthodes de Monte Carlo à grande
échelle, tandis que le CPU reste pertinent pour des tailles de problèmes plus
modérées ou lorsque la simplicité d'implémentation est prioritaire.



\subsection{Discussion sur les limites du parallélisme}

Les résultats confirment que l’algorithme LSMC est naturellement bien adapté au parallélisme spatial, mais intrinsèquement limité par sa structure séquentielle dans le temps. En effet, l'algorithme repose sur une \textbf{induction arrière} (backward induction) : le calcul des valeurs à l'étape $t$ dépend mathématiquement des résultats de l'étape $t+1$ (nécessaires pour construire la variable cible de la régression).

Il est donc impossible de paralléliser le traitement des différents pas de temps pour une même option. Le GPU doit impérativement attendre la fin du calcul de l'étape $t+1$ avant de commencer l'étape $t$, ce qui crée une barrière de synchronisation inévitable. L'accélération maximale est ainsi plafonnée par cette contrainte séquentielle, même avec un nombre infini de cœurs. La seule manière d'accroître davantage le parallélisme serait de traiter simultanément plusieurs options distinctes (batching).

Ces observations expliquent pourquoi les gains GPU, bien que très importants, ne peuvent pas être parfaitement linéaires avec la puissance de calcul.

Ces résultats mettent en évidence l’intérêt d’architectures hybrides CPU--GPU, ainsi que l’importance de choix d’implémentation fins (organisation mémoire, réductions efficaces, limitation des synchronisations) pour exploiter pleinement les capacités du matériel moderne.

\textbf{Synthèse Globale :} Si le GPU déverrouille la scalabilité spatiale du stock de trajectoires, la dimension temporelle reste séquentielle. L'optimum de performance réside dans un équilibre : assez de trajectoires pour saturer le GPU, mais pas au-delà des besoins de précision, car le coût de régression devient alors prépondérant.

\newpage
\section{Analyse Critique et Limitations}

La réalisation de ce projet a mis en évidence plusieurs défis techniques et méthodologiques, dont l'analyse permet de mieux cerner les contraintes du calcul haute performance en finance.

\subsection{Organisation du projet et évolution des dépôts}

Le développement du projet s'est articulé autour de \textbf{deux dépôts Git distincts}, reflétant une évolution technique majeure :

\begin{enumerate}
    \item \textbf{lsmc-openmp}\footnote{\url{https://github.com/FlorianBarbe/lsmc-openmp}} (Octobre 2025) : Le premier dépôt a été consacré au développement de la logique métier de l'algorithme LSMC en C++ avec parallélisation OpenMP. Le système de build reposait sur des solutions \texttt{Visual Studio} (.sln, .vcxproj). Ce dépôt inclut également une interface graphique en Python (Streamlit/Matplotlib) pour la visualisation des trajectoires.
    
    \item \textbf{CUDA-Implementation}\footnote{\url{https://github.com/FlorianBarbe/CUDA-Implementation-of-the-Longstaff-Schwartz-Method-for-American-Option-Pricing}} (Janvier 2026) : Face aux difficultés d'intégration CUDA dans le premier dépôt, un second dépôt a été créé avec une architecture repensée autour de \textbf{CMake}. C'est dans ce dépôt que les fonctionnalités avancées (5 bases de régression, solveur générique, kernels optimisés) ont été développées et validées.
\end{enumerate}

Cette organisation permet de conserver une \textbf{version CPU de référence} (premier dépôt) tout en disposant d'une \textbf{version HPC/GPU complète} (second dépôt).

\subsection{Échec de l'intégration CUDA dans Visual Studio}

L'historique des commits du premier dépôt témoigne des tentatives infructueuses d'intégration CUDA :
\begin{itemize}
    \item \textit{"Début intégration CUDA"} : ajout initial des fichiers .cu et configuration NVCC.
    \item \textit{"On continue de debug CUDA car rien ne marche"} : erreurs de compilation persistantes.
    \item \textit{"Suppression complète de tout le code lié à CUDA/GPU"} : abandon de l'approche.
\end{itemize}

\textbf{Cause identifiée :} Visual Studio peinait à gérer correctement la cohabitation entre le compilateur C++ standard (MSVC) et le compilateur CUDA (\texttt{nvcc}). Les conflits de flags de compilation, les incompatibilités d'architectures cibles et la gestion des dépendances rendaient la configuration instable.

\textbf{Solution adoptée :} La migration vers \textbf{CMake} a résolu ces problèmes. CMake intègre nativement le support CUDA via \texttt{enable\_language(CUDA)} et permet une séparation propre entre le code hôte (.cpp) et le code device (.cu). Cette architecture a permis de finaliser l'implémentation GPU avec succès.

\subsection{Complexité de l’exercice anticipé}

La difficulté théorique majeure provient de la possibilité d’un exercice anticipé
pour les options américaines. Cette caractéristique transforme le problème de
valorisation en un problème d’arrêt optimal, nécessitant une estimation fiable
de la valeur de continuation à chaque date. Une mauvaise compréhension de cette
quantité conduit rapidement à des erreurs de logique dans la backward induction.
Un soin particulier a donc été apporté à la séparation claire entre valeur
d’exercice immédiat et valeur de continuation estimée.

\subsection{Choix, stabilité et extensions de la régression}

L’estimation de la valeur de continuation par régression constitue un point
sensible de l’algorithme. Le choix des fonctions de base représente un compromis
entre précision et stabilité numérique. Des bases trop simples introduisent un
biais, tandis que des bases trop riches peuvent engendrer des instabilités ou un
surcoût de calcul.

\paragraph{Étude initiale : Bases quadratiques.}
Dans un premier temps, une étude comparative a été menée entre la base canonique $(1, S, S^2)$ et la base de \textbf{polynômes d'Hermite de degré 2} $(1, S, S^2-1)$. Bien que les benchmarks montrent peu de différence en termes de précision pour ce problème spécifique, la base d'Hermite a été retenue par défaut pour ses meilleures propriétés théoriques de conditionnement (matrice $A^T A$).

\paragraph{Extensions et bases avancées.}
Afin d'affiner la capture de la valeur de continuation, nous avons étendu l'implémentation à trois autres familles de bases, souvent citées dans la littérature spécialisée \cite{Hull} :
\begin{enumerate}
    \item \textbf{Laguerre} : Polynômes orthogonaux sur $[0, \infty[$, historiquement suggérés par Longstaff et Schwartz \cite{LSM2001} pour leur adaptation naturelle aux prix d'actifs positifs (pondération par exponentielle décroissante).
    \item \textbf{Tchebychev} : Polynômes minimisant l'erreur d'interpolation sur $[-1, 1]$. Cette base a nécessité l'implémentation d'un kernel de réduction Min-Max sur GPU pour normaliser les prix à chaque pas de temps.
    \item \textbf{Cubique} : Base monômiale enrichie au degré 3 $(1, S, S^2, S^3)$.
\end{enumerate}


La figure~\ref{fig:basis_comparison} illustre l'impact du choix de la base de régression sur la précision de l'estimation.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\linewidth]{images/precision_convergence_full.png}
    \caption{Comparaison de la convergence de l'erreur relative selon le nombre de trajectoires ($N=10^4, 10^5$) et l'architecture.}
    \label{fig:degree_convergence_full}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\linewidth]{images/convergence_theorique_areal.png}
    \caption{Évolution théorique attendue de la précision (Source: \cite{ArealParallelMethods}). Voici ce que l'on devrait observer idéalement.}
    \label{fig:basis_comparison}
\end{figure}

\paragraph{Analyse de la convergence (Figure~\ref{fig:degree_convergence_full}).}
Les résultats présentés en figure~\ref{fig:degree_convergence_full} montrent l'évolution de l'erreur relative par rapport au prix RK4 de référence. Cette dynamique peut être mise en perspective avec la Figure~\ref{fig:basis_comparison} (issue de \cite{ArealParallelMethods}) qui illustre les attentes théoriques de convergence.
Contrairement à l'intuition théorique qui suggère une amélioration monotone, les courbes observées ne présentent pas une décroissance régulière.
Plusieurs facteurs peuvent expliquer ce comportement mitigé et "non concluant" sur ce cas test spécifique :
\begin{itemize}
    \item \textbf{Phénomène de Runge :} L'utilisation de bases polynomiales de degré élevé sur des points non uniformément répartis (les trajectoires stochastiques) peut induire de fortes oscillations aux bords du domaine (valeurs extrêmes de $S_t$), dégradant la qualité globale de la régression \cite{Glasserman}.
    \item \textbf{Conditionnement de la matrice :} Pour des degrés élevés ($d > 5$), la matrice de Gram $A^T A$ devient mal conditionnée, en particulier pour la base Monomiale, ce qui amplifie les erreurs numériques lors de la résolution du système linéaire. Bien que les bases orthogonales (Laguerre, Hermite) soient censées atténuer ce problème, le bruit de Monte Carlo semble ici dominer les gains théoriques.
    \item \textbf{Compromis Biais-Variance :} Augmenter le degré réduit le biais de modélisation (capacité à fitter la "vraie" fonction de continuation) mais augmente la variance de l'estimateur, car le modèle capture le bruit statistique des trajectoires (sur-apprentissage).
\end{itemize}
Ces observations soulignent la difficulté pratique d'obtenir une convergence "parfaite" avec des méthodes de régression globale sur des degrés élevés sans un nombre de trajectoires extrêmement grand ($N \gg 10^5$).



\subsection{Compromis précision--performance}

Enfin, ce projet a mis en évidence le compromis fondamental entre précision
numérique et temps de calcul. L’augmentation du nombre de trajectoires améliore
la convergence statistique, mais accroît fortement le coût de calcul, en
particulier lors des phases de régression et de backward induction. Ce compromis
a guidé le choix des paramètres expérimentaux et l’analyse comparative des
architectures CPU et GPU.

\newpage
\section{Perspectives et améliorations possibles}

Le travail réalisé dans le cadre de ce projet a permis de mettre en œuvre une version fonctionnelle et performante de l’algorithme de Longstaff--Schwartz sur différentes architectures de calcul. Plusieurs pistes d’amélioration et d’extension peuvent toutefois être envisagées, tant sur le plan algorithmique que sur le plan des performances et des modèles financiers considérés.

\subsection{Améliorations algorithmiques}

Une première piste d’amélioration concerne le choix des fonctions de base utilisées pour l’approximation de la valeur de continuation. Dans ce projet, une base polynomiale simple de degré deux a été retenue pour des raisons de simplicité et de stabilité numérique. Il serait possible d’explorer :
\begin{itemize}
    \item l'utilisation de méthodes de \textbf{Monte Carlo Multi-Niveaux (MLMC)} \cite{Ghodssi} pour réduire la variance et le coût de calcul ;
    \item la mise en œuvre de \textbf{régressions locales} (Local Least Squares) \cite{Detra}, permettant une meilleure capture des non-linéarités de la fonction de continuation ;
    \item l'exploration d'approches de \textbf{parallélisation temporelle} (type Parareal) \cite{Parareal} afin de surmonter la contrainte séquentielle de la backward induction.
\end{itemize}

Ces choix peuvent améliorer la précision de l’estimation de la valeur de continuation, au prix d’un coût de calcul plus élevé et d’un risque accru de sur-apprentissage.

Par ailleurs, l’utilisation de techniques de réduction de variance (antithetic variates, control variates, stratified sampling) pourrait significativement améliorer la convergence statistique de la méthode de Monte Carlo, en réduisant le nombre de trajectoires nécessaires pour atteindre une précision donnée.

\subsection{Extensions du modèle financier}

Le cadre retenu dans ce projet repose sur un mouvement brownien géométrique, modèle de référence mais relativement simplificateur. Plusieurs extensions naturelles peuvent être envisagées :
\begin{itemize}
    \item introduction d’un taux de dividende continu ;
    \item prise en compte d’une volatilité locale ou stochastique (modèles de Heston, SABR) ;
    \item extension à des options multi-actifs ou dépendant de plusieurs sous-jacents ;
    \item valorisation de produits exotiques présentant des payoffs path-dépendants.
\end{itemize}

L’algorithme de Longstaff--Schwartz conserve une grande flexibilité face à ces extensions, ce qui constitue l’un de ses principaux avantages par rapport aux méthodes analytiques.

\subsection{Optimisations CPU avancées}

Sur CPU, plusieurs optimisations supplémentaires pourraient être envisagées :
\begin{itemize}
    \item vectorisation explicite via les instructions SIMD (AVX2, AVX-512) ;
    \item meilleure gestion de la localité mémoire pour réduire la pression sur la bande passante RAM ;
    \item utilisation de bibliothèques numériques optimisées pour les régressions linéaires.
\end{itemize}

Ces optimisations permettraient d’exploiter plus finement l’architecture matérielle, en particulier pour des tailles de problème intermédiaires où le GPU n’est pas toujours optimal.

\subsection{Optimisation et généralisation de l’implémentation GPU}

Du côté GPU, plusieurs améliorations sont envisageables :
\begin{itemize}
    \item implémentation complète de la régression par moindres carrés directement sur GPU, sans synchronisation CPU ;
    \item utilisation de bibliothèques CUDA spécialisées (\texttt{cuBLAS}, \texttt{CUB}, \texttt{Thrust}) pour les réductions et opérations linéaires ;
    \item exploration de stratégies multi-GPU pour des simulations de très grande dimension.
\end{itemize}

Une telle approche permettrait de réduire encore les coûts de communication et d’atteindre des gains de performance plus proches du potentiel théorique du GPU.

\subsection{Perspectives méthodologiques}

Enfin, ce projet ouvre la voie à des comparaisons plus larges entre différentes approches numériques pour le pricing d’options américaines. Comme illustré par la Figure~\ref{fig:binomial_tree}, il serait intéressant de confronter les performances du LSMC à :
\begin{itemize}
    \item \textbf{les méthodes par arbres} (Binomiaux, Trinômiaux) : très utilisées pour leur flexibilité sur les options américaines (simple dimension) ;
    \item \textbf{les méthodes itératives} (Différences Finies) : qui résolvent l'EDP de Black-Scholes-Merton avec condition de frontière libre ($P \ge (K-S)^+$) ;
    \item \textbf{les méthodes spectrales} (Transformée de Fourier) : permettant des évaluations très rapides pour certains modèles (e.g., Heston, Lévy), bien que moins naturellement adaptées à l'exercice anticipé américain (nécessitant des techniques type méthodes de Spitzer).
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{images/binomial_tree.png}
    \caption{Illustration d'un arbre binomial pour la valorisation d'options.}
    \label{fig:binomial_tree}
\end{figure}

Ces perspectives permettraient d’évaluer plus finement les compromis entre précision, coût de calcul et flexibilité des différentes méthodes, dans un contexte de finance quantitative moderne.

\section{Organisation du travail}

Le projet P1RV a été mené sur l’ensemble du premier semestre selon une
organisation progressive, combinant approfondissement théorique,
développement logiciel itératif et analyse des performances.  
Le travail s’est appuyé sur une démarche incrémentale, avec des phases
successives de conception, d’implémentation, de refactorisation et
d’optimisation, comme en témoigne l’historique détaillé du dépôt Git.

\subsection{Découpage du projet}

Le développement du projet a été structuré autour des grandes étapes suivantes :
\begin{itemize}
    \item étude du cadre théorique : options américaines, Monte Carlo,
    backward induction et algorithme de Longstaff--Schwartz ;
    \item implémentation d’une version CPU séquentielle servant de référence ;
    \item restructuration complète du code afin de séparer clairement
    simulation, régression et logique LSMC ;
    \item parallélisation CPU avec OpenMP ;
    \item ajout progressif d’un backend GPU CUDA expérimental ;
    \item mise en place d’outils d’export des résultats (CSV) et de visualisation ;
    \item campagnes de tests, mesures de performances et nettoyage final du code ;
    \item rédaction et structuration du rapport.
\end{itemize}

Ce découpage a permis de valider progressivement chaque brique fonctionnelle
avant d’aborder les aspects avancés de parallélisation et d’optimisation.

\subsection{Organisation du développement et itérations}

Le développement s’est appuyé sur un processus itératif, visible dans
l’historique du dépôt Git :
\begin{itemize}
    \item création initiale du projet et mise en place de la structure
    \texttt{src/include} ;
    \item premières implémentations du GBM, de la régression OLS et du LSMC ;
    \item phases de refonte complètes du code afin d’améliorer la lisibilité,
    la modularité et les performances ;
    \item intégration progressive d’OpenMP sur les boucles critiques ;
    \item ajout d’une interface de visualisation et d’export des résultats
    (scripts Python, Streamlit) ;
    \item implémentation d’un backend CUDA complet incluant la simulation GBM,
    le calcul des payoffs, la backward induction et les réductions nécessaires
    à la régression ;
    \item nettoyage approfondi du dépôt après des problèmes liés à des fichiers
    CSV volumineux et à l’historique Git.
\end{itemize}

Cette approche incrémentale a permis de maintenir un code fonctionnel à chaque
étape tout en introduisant progressivement des optimisations plus complexes.

Dans la phase initiale du projet (dépôt \texttt{lsmc-openmp}), une interface graphique expérimentale a été développée en Python pour faciliter l'appropriation du modèle et le débogage visuel. Elle permettait de paramétrer la simulation ($S_0, K, r, \sigma, T$), de lancer l'exécutable C++ en arrière-plan et de visualiser dynamiquement les trajectoires exportées (Figure~\ref{fig:python_gui}).

Bien qu'abandonnée pour les benchmarks finaux au profit de scripts CLI plus adaptés au calcul haute performance, cette interface a joué un rôle pédagogique crucial pour valider notre compréhension de la diffusion du sous-jacent et du mécanisme de Monte Carlo.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\linewidth]{images/python_gui_1.jpg}
    \caption{Interface de paramétrage et de lancement (Projet Initial \texttt{lsmc-openmp}).}
    \label{fig:python_gui}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\linewidth]{images/python_gui_2.jpg}
    \caption{Visualisation des trajectoires Monte Carlo et du prix estimé via l'interface Python.}
    \label{fig:python_gui_2}
\end{figure}

\subsection{Répartition des tâches et binôme}

Afin d'optimiser notre efficacité, nous nous sommes réparti les tâches selon nos affinités et compétences techniques.

\subsubsection*{Responsabilités Techniques}

\textbf{Narjisse El Manssouri} a pris la responsabilité de l'expérience utilisateur, de l'interface (\emph{Frontend}) et de la validation théorique :
\begin{itemize}
    \item Conception de l'interface graphique (GUI) pour rendre l'outil accessible.
    \item Développement de l'application interactive Python.
    \item Visualisation des résultats (trajectoires, convergence) et validation de la cohérence théorique.
\end{itemize}

\textbf{Florian Barbe} a pris la responsabilité du "cœur de calcul" (\emph{Core Engine}). Son travail s'est concentré sur la performance et l'architecture logicielle C++/CUDA :
\begin{itemize}
    \item Modélisation mathématique et implémentation C++.
    \item Développement de l'algorithme LSMC et des solveurs FDM.
    \item Parallélisation CPU avec OpenMP.
    \item Développement complet du kernel CUDA et de l'implémentation GPU.
    \item Benchmarking et optimisation des performances bas niveau.
\end{itemize}

\subsection{Retours d'expérience et témoignages}

Au-delà de la répartition technique, ce projet a été l'occasion d'une montée en compétence individuelle.

\subsubsection*{Narjisse El Manssouri}

\begin{quote}
"La principale difficulté a été de savoir dans quelle direction avancer au début du projet : je comprenais déjà l’objet financier d’une option américaine, mais pas les mathématiques et la logique algorithmique derrière le pricing. De ce fait, l’entrée en matière a été plus lente, notamment pour comprendre la structure du code que l’on pouvait et devait faire, ainsi que la façon dont l’exercice anticipé est traité avant de pouvoir coder efficacement.

Ma contribution s’est donc d’abord orientée vers la partie théorique, afin de clarifier les hypothèses, le déroulé de la méthode de simulation et le rôle de chaque bloc du programme, puis vers la réalisation d’une interface graphique en Python pour rendre l’outil exploitable et lisible : elle permet de saisir les paramètres ($S_0, K, r, \sigma, T$), de choisir le nombre de pas de temps et de trajectoires, de lancer l’exécutable C++ et suivre son exécution via une console intégrée, d’exporter les trajectoires en CSV, puis de charger et visualiser les chemins Monte Carlo sur un graphique avec un récapitulatif du prix estimé.

J’ai particulièrement apprécié ce projet car il correspond exactement à ce que je cherchais dans mon option : consolider des bases en C++ et en simulation de données, tout en les appliquant à un cas concret de finance de marché, avec un vrai enjeu de compréhension méthodologique et de mise en production via un outil de visualisation."
\end{quote}

\subsubsection*{Florian Barbe}

\begin{quote}
"Ma contribution s’est principalement concentrée sur la partie algorithmique et les aspects de performance du projet. L’une des premières difficultés a été de bien me situer dans le cadre financier des options américaines. Si le principe général était clair, la logique de l’exercice anticipé et son impact sur la structure du calcul demandaient une compréhension plus fine pour pouvoir être traduits correctement en algorithme. Cette phase a été plus longue que prévu, mais elle a été essentielle pour comprendre le fonctionnement global du LSMC et éviter une implémentation purement mécanique.

La mise en œuvre de l’accélération GPU avec CUDA a également représenté un défi important. Les premières tentatives d’intégration se sont révélées complexes, tant sur le plan de l’architecture du code que de la gestion mémoire et des synchronisations imposées par la backward induction. Ces difficultés ont conduit à la décision de créer un second dépôt Git, spécifiquement dédié à une implémentation plus propre et mieux adaptée au calcul sur GPU.

Ce projet a néanmoins été particulièrement stimulant sur le plan technique. Le moment où les premiers tests sur GPU ont montré des temps de calcul largement inférieurs aux versions CPU a été un soulagement, vu le nombre d'heures que j'avais passées dessus sans succès. Voir concrètement des calculs de Monte Carlo s’exécuter en une fraction du temps initial a été très motivant et a donné un sens immédiat aux efforts fournis en optimisation et en parallélisation. Cette expérience a renforcé mon intérêt pour le calcul parallèle et m’a permis de mesurer de manière très concrète l’impact des choix d’architecture et d’implémentation sur les performances."
\end{quote}

Cette séparation claire (Back-end en C++/CUDA vs Front-end en Python) nous a permis d'avancer en parallèle : pendant que le moteur de calcul était optimisé, l'interface utilisateur était développée pour consommer les résultats produits.

\subsection{Outils et environnement collaboratif}

Le projet s’est appuyé sur les outils suivants :
\begin{itemize}
    \item \textbf{Git / GitHub} pour le suivi du développement et l’historique
    des itérations ;
    \item \textbf{CMake} pour la configuration et la compilation du projet ;
    \item \textbf{OpenMP} pour la parallélisation CPU ;
    \item \textbf{CUDA C++} pour l’implémentation GPU ;
    \item \textbf{Python} et \textbf{Streamlit} pour l’analyse et la visualisation
    des résultats ;
    \item \textbf{Overleaf} pour la rédaction du rapport.
\end{itemize}

L’utilisation intensive de Git a joué un rôle central, notamment pour gérer
les phases de refonte, corriger des erreurs structurelles (fichiers volumineux,
historique trop lourd) et stabiliser le dépôt en fin de projet.

\subsection{Gestion du temps et avancement}

Le travail a été réparti sur l’ensemble du semestre avec une montée en complexité
progressive :
\begin{itemize}
    \item début de semestre : compréhension théorique, premières implémentations
    CPU séquentielles ;
    \item milieu de semestre : restructuration du code, parallélisation OpenMP,
    premières analyses de performance ;
    \item fin de semestre : implémentation CUDA complète, optimisation mémoire,
    nettoyage du dépôt Git, analyse comparative et rédaction finale.
\end{itemize}

Cette organisation a permis d’anticiper les difficultés techniques, notamment
celles liées au calcul parallèle, à la gestion mémoire et aux limitations
structurelles de l’algorithme LSMC, tout en assurant la livraison d’un projet
fonctionnel, documenté et cohérent avec les objectifs pédagogiques du P1RV.



\newpage
\section{Conclusion}

Ce projet a permis de concevoir, implémenter et analyser une version performante de l’algorithme de Longstaff–Schwartz pour le pricing d’options américaines, en combinant rigueur mathématique, validation numérique et étude approfondie des performances sur différentes architectures de calcul.

L’implémentation séquentielle sur CPU a servi de référence fonctionnelle et a permis de valider la cohérence de l’algorithme. La parallélisation via OpenMP a montré des gains mesurés mais limités, principalement contraints par la bande passante mémoire et la présence de phases séquentielles incompressibles. En revanche, l’implémentation GPU avec CUDA a démontré des accélérations significatives pour les phases massivement parallèles, en particulier la simulation Monte Carlo des trajectoires, avec des speedups pouvant atteindre un ordre de grandeur par rapport au CPU.

Les résultats obtenus mettent toutefois en évidence une limite structurelle fondamentale du LSMC : la backward induction impose une dépendance temporelle forte qui empêche toute parallélisation complète dans la dimension du temps. Le goulot d’étranglement réside donc dans l’estimation séquentielle de la valeur de continuation à chaque pas de temps, ce qui plafonne l’accélération théorique, même sur des architectures massivement parallèles.

La validation croisée avec des méthodes déterministes de différences finies a confirmé la cohérence numérique des prix obtenus, les écarts restant compatibles avec la variance statistique attendue d’une méthode de Monte Carlo. L’étude du choix des bases de régression a par ailleurs mis en évidence le compromis biais–variance inhérent à l’algorithme, ainsi que les limites pratiques des régressions polynomiales de degré élevé en présence de bruit stochastique.

En conclusion, ce travail montre que le GPU constitue une solution particulièrement adaptée pour les méthodes de Monte Carlo à grande échelle, tout en soulignant que les gains de performance sont intrinsèquement bornés par la structure algorithmique du LSMC. Ces résultats ouvrent la voie à des approches hybrides (batching d'options, parallélisme asynchrone) visant à contourner la barrière séquentielle temporelle, seule restriction à l'essor du LSMC sur les architectures exascale.


\clearpage
\appendix

\section{Résolution de l'EDS du GBM}
\label{appendix:eds}

On considère le processus \((S_t)_{t \ge 0}\) solution, sous la mesure risque-neutre \(\mathbb{Q}\), de l’équation différentielle stochastique
\[
\mathrm{d}S_t = r S_t\,\mathrm{d}t + \sigma S_t\,\mathrm{d}W_t^{\mathbb{Q}},
\]

où \(r\) est le taux sans risque, \(\sigma>0\) la volatilité constante, et \((W_t^{\mathbb{Q}})_{t\ge 0}\) un mouvement brownien standard sous \(\mathbb{Q}\).

Comme \(S_t>0\) presque sûrement, la fonction \(\ln\) est bien définie. En appliquant la formule d’Itô à \(f(S_t)=\ln(S_t)\), on obtient
\[
\mathrm{d}\ln(S_t)
=
f'(S_t)\,\mathrm{d}S_t
+\frac12 f''(S_t)\,(\mathrm{d}S_t)^2
=
\frac{1}{S_t}\,\mathrm{d}S_t
-\frac{1}{2S_t^2}(\mathrm{d}S_t)^2.
\]

En utilisant les règles du calcul stochastique
\[
(\mathrm{d}W_t^{\mathbb{Q}})^2=\mathrm{d}t,
\qquad
\mathrm{d}t\,\mathrm{d}W_t^{\mathbb{Q}}=0,
\qquad
(\mathrm{d}t)^2=0,
\]
on a
\[
\mathrm{d}S_t = r S_t\,\mathrm{d}t + \sigma S_t\,\mathrm{d}W_t^{\mathbb{Q}}
\quad \Longrightarrow \quad
(\mathrm{d}S_t)^2 = \sigma^2 S_t^2\,(\mathrm{d}W_t^{\mathbb{Q}})^2=\sigma^2 S_t^2\,\mathrm{d}t.
\]

En substituant dans la formule d’Itô, il vient
\[
\mathrm{d}\ln(S_t)
=
\frac{1}{S_t}\Bigl(r S_t\,\mathrm{d}t + \sigma S_t\,\mathrm{d}W_t^{\mathbb{Q}}\Bigr)
-\frac{1}{2S_t^2}\Bigl(\sigma^2 S_t^2\,\mathrm{d}t\Bigr),
\]
soit
\[
\mathrm{d}\ln(S_t)
=
\left(r-\frac{\sigma^2}{2}\right)\mathrm{d}t
+\sigma\,\mathrm{d}W_t^{\mathbb{Q}}.
\]

En intégrant entre \(t_n\) et \(t_{n+1}\) (avec \(\Delta t = t_{n+1}-t_n\)) :
\[
\ln(S_{t_{n+1}})-\ln(S_{t_n})
=
\left(r-\frac{\sigma^2}{2}\right)\Delta t
+\sigma\bigl(W_{t_{n+1}}^{\mathbb{Q}}-W_{t_n}^{\mathbb{Q}}\bigr).
\]

Les incréments du mouvement brownien sous \(\mathbb{Q}\) vérifient
\[
W_{t_{n+1}}^{\mathbb{Q}}-W_{t_n}^{\mathbb{Q}} \sim \mathcal{N}(0,\Delta t).
\]
Il existe donc \(Z_n \sim \mathcal{N}(0,1)\) tel que
\[
W_{t_{n+1}}^{\mathbb{Q}}-W_{t_n}^{\mathbb{Q}}=\sqrt{\Delta t}\,Z_n.
\]

En prenant l'exponentielle, on obtient la formule discrète exacte
\[
S_{t_{n+1}}
=
S_{t_n}\exp\!\left(
\left(r-\frac{\sigma^2}{2}\right)\Delta t
+\sigma\sqrt{\Delta t}\,Z_n
\right),
\]
et, en particulier, l’expression explicite en temps continu
\[
S_t
=
S_0\exp\!\left(
\left(r-\frac{\sigma^2}{2}\right)t
+\sigma W_t^{\mathbb{Q}}
\right).
\]




\clearpage
\section{Rappels de Probabilités et propriétés du Mouvement Brownien}
\label{appendix:brownian}

\subsection{Définition et propriétés du Mouvement Brownien}
Un mouvement brownien standard $(W_t)_{t \ge 0}$ est un processus stochastique caractérisé par :
\begin{enumerate}
    \item $W_0 = 0$ presque sûrement.
    \item Ses trajectoires $t \mapsto W_t$ sont continues.
    \item Ses accroissements sont indépendants et stationnaires (loi normale $\mathcal{N}(0, t-s)$ pour $W_t - W_s$).
\end{enumerate}

\subsection{Propriétés des incréments}
Pour la simulation numérique, nous utilisons la propriété d'indépendance des accroissements sur des intervalles disjoints. Si $0 \le t_1 < t_2 < \dots < t_n$, les variables aléatoires $(W_{t_{i+1}} - W_{t_i})$ sont mutuellement indépendantes.

\subsection{Loi des Grands Nombres et Monte Carlo}
La convergence des méthodes de Monte Carlo repose sur la Loi Forte des Grands Nombres (LFGN) :
\[ \lim_{N \to \infty} \frac{1}{N} \sum_{i=1}^N f(X_i) = \mathbb{E}[f(X)] \quad \text{p.s.} \]
L'erreur d'approximation décroît en $\mathcal{O}(1/\sqrt{N})$, conformément au Théorème Central Limite.

\clearpage
\section{Propriétés des Bases Polynomiales et Relations de Récurrence}
\label{appendix:polys}

Cette annexe détaille les propriétés mathématiques des bases de régression implémentées.

\subsection{Base Canonique (Monomiale)}
Base la plus simple, définie par $P_n(x) = x^n$.
Elle n'est pas orthogonale pour le produit scalaire standard, ce qui conduit à des matrices de Gram $(A^TA)$ mal conditionnées (problème de la matrice de Hilbert) lorsque le degré augmente.

\subsection{Polynômes de Laguerre $L_n(x)$}
Orthogonaux sur $[0, +\infty[$ pour le poids $w(x) = e^{-x}$. Adaptés pour modéliser des fonctions de variables positives (comme les prix d'actifs).
\begin{itemize}
    \item $L_0(x) = 1$
    \item $L_1(x) = 1 - x$
    \item Récurrence : $(n+1)L_{n+1}(x) = (2n+1-x)L_n(x) - nL_{n-1}(x)$
\end{itemize}

\subsection{Polynômes d'Hermite $H_n(x)$}
Orthogonaux sur $]-\infty, +\infty[$ pour le poids $w(x) = e^{-x^2}$. Naturellement liés à la loi Normale.
\begin{itemize}
    \item $H_0(x) = 1$
    \item $H_1(x) = 2x$
    \item Récurrence : $H_{n+1}(x) = 2xH_n(x) - 2nH_{n-1}(x)$
\end{itemize}

\subsection{Polynômes de Legendre $P_n(x)$}
Orthogonaux sur $[-1, 1]$ pour le poids $w(x) = 1$. Nécessitent de redimensionner les variables (scaling) dans l'intervalle $[-1, 1]$ avant régression.
\begin{itemize}
    \item $P_0(x) = 1$
    \item $P_1(x) = x$
    \item Récurrence : $(n+1)P_{n+1}(x) = (2n+1)xP_n(x) - nP_{n-1}(x)$
\end{itemize}

\subsection{Polynômes de Chebyshev (1ère espèce) $T_n(x)$}
Orthogonaux sur $[-1, 1]$ pour le poids $w(x) = \frac{1}{\sqrt{1-x^2}}$. Ils minimisent l'effet de Runge (oscillation aux bords) en interpolation.
\begin{itemize}
    \item $T_0(x) = 1$
    \item $T_1(x) = x$
    \item Récurrence : $T_{n+1}(x) = 2xT_n(x) - T_{n-1}(x)$
\end{itemize}

\clearpage
\section{Notations et Conventions}
\label{appendix:notations}

\subsection{Probabilités et Processus Stochastiques}
\begin{center}
\renewcommand{\arraystretch}{1.5}
\begin{longtable}{|c|p{12cm}|}
\hline
\textbf{Notation} & \textbf{Description} \\
\hline
$\Omega, \mathcal{F}, \mathbb{P}$ & Espace probabilisé filtré standard. \\
$\mathbb{Q}$ & Mesure risque-neutre, sous laquelle les actifs actualisés sont des martingales. \\
$(\mathcal{F}_t)_{t \ge 0}$ & Filtration naturelle engendrée par le mouvement brownien, représentant l'information disponible à l'instant $t$. \\
$W_t^{\mathbb{Q}}$ & Mouvement Brownien standard sous la mesure $\mathbb{Q}$. \\
$S_t$ & Valeur du sous-jacent à l'instant $t$. \\
$\mathbb{E}^{\mathbb{Q}}[\cdot | \mathcal{F}_t]$ & Espérance conditionnelle sous la mesure $\mathbb{Q}$ sachant l'information à l'instant $t$. \\
\hline
\end{longtable}
\end{center}

\subsection{Modélisation Financière}
\begin{center}
\renewcommand{\arraystretch}{1.5}
\begin{longtable}{|c|p{12cm}|}
\hline
\textbf{Notation} & \textbf{Description} \\
\hline
$S_0$ & Prix initial du sous-jacent ($t=0$). \\
$K$ & Prix d'exercice (Strike) de l'option. \\
$T$ & Maturité de l'option (en années). \\
$r$ & Taux d'intérêt sans risque constant. \\
$\sigma$ & Volatilité constante du sous-jacent. \\
$\Phi(S)$ & Fonction de payoff ou valeur intrinsèque. Pour un Put : $\Phi(S) = (K-S)^+$. \\
$V_t$ & Prix de l'option américaine à l'instant $t$. \\
$C(t, S_t)$ & Valeur de continuation à l'instant $t$ sachant $S_t$. \\
$\tau$ & Temps d'arrêt correspondant à la stratégie d'exercice optimale. \\
\hline
\end{longtable}
\end{center}

\subsection{Méthodes Numériques (LSMC)}
\begin{center}
\renewcommand{\arraystretch}{1.5}
\begin{longtable}{|c|p{12cm}|}
\hline
\textbf{Notation} & \textbf{Description} \\
\hline
$N \text{ ou } N_{steps}$ & Nombre de pas de temps de la discrétisation. \\
$\Delta t$ & Pas de temps uniforme ($\Delta t = T/N$). \\
$t_n$ & Dates de discrétisation ($t_n = n \Delta t$). \\
$M \text{ ou } N_{paths}$ & Nombre de trajectoires Monte Carlo simulées. \\
$S_{t_n}^{(i)}$ & Valeur simulée du sous-jacent pour la trajectoire $i$ à l'instant $t_n$. \\
$\psi_k(S)$ & $k$-ième fonction de base utilisée pour la régression. \\
$K_{reg}$ & Nombre total de fonctions de base (e.g., $3$ pour quadratique). \\
$\beta$ (ou $a_k$) & Vecteur des coefficients de régression estimés. \\
$\widehat{C}(t_n, S)$ & Estimateur numérique de la valeur de continuation obtenue par régression. \\
$A$ & Matrice de design (Vandermonde généralisée) utilisée dans les moindres carrés ($A^T A \beta = A^T Y$). \\
\hline
\end{longtable}
\end{center}

\subsection{Implémentation et Architecture}
\begin{center}
\renewcommand{\arraystretch}{1.5}
\begin{longtable}{|c|p{12cm}|}
\hline
\textbf{Notation} & \textbf{Description} \\
\hline
OpenMP & \textit{Open Multi-Processing}, API pour la programmation parallèle sur mémoire partagée (CPU). \\
CUDA & \textit{Compute Unified Device Architecture}, plateforme de calcul parallèle NVIDIA. \\
Thread & Unité d'exécution de base. Sur GPU, un thread traite typiquement une trajectoire simulée. \\
Block & Regroupement de threads sur GPU partageant une mémoire locale (Shared Memory). \\
Grid & Ensemble des blocs lancés pour l'exécution d'un Kernel CUDA. \\
Kernel & Fonction exécutée sur le GPU par chaque thread de la grille. \\
Speedup & Gain de performance, défini comme $\text{Temps}_{CPU} / \text{Temps}_{GPU}$. \\
\hline
\end{longtable}
\end{center}

\clearpage
\begin{thebibliography}{9}

\bibitem{LSM2001}
Longstaff, F. A., \& Schwartz, E. S. (2001).
\textit{Valuing American Options by Simulation: A Simple Least-Squares Approach}.
The Review of Financial Studies, 14(1), 113-147.

\bibitem{Hull}
Hull, J. C.
\textit{Options, Futures, and Other Derivatives}.
Pearson Education.

\bibitem{Glasserman}
Glasserman, P. (2004).
\textit{Monte Carlo Methods in Financial Engineering}.
Springer.

\bibitem{Oger}
Oger, G.
\textit{Mémoire de Magistère : Valorisation d'options américaines sur GPU}.

\bibitem{Croain}
Croain, D., \& Poulette.
\textit{Projet GPU : Pricing d'options américaines}.

\bibitem{Risks}
Risks Journal (2023).
\textit{Recent Advances in American Option Pricing}.
risks-11-00145.


\bibitem{Benguigui}
Benguigui, M. (2015).
\textit{Valorisation d'options américaines et Value At Risk sur cluster GPU/CPU hétérogène}.
Thèse de doctorat, Université Nice Sophia Antipolis.

\bibitem{Reesor}
Reesor, R. M., Stentoft, L., \& Zhu, X. (2024).
\textit{A Critical Analysis of the Weighted Least Squares Monte Carlo Method for Pricing American Options}.
Finance Research Letters.

\bibitem{ArealParallelMethods}
Areal, N., Rodrigues, A., \& Armada, M. J. R.
\textit{Improvements to the Least Squares Monte Carlo Option Valuation Method}.
Source file: \texttt{Areal\_Parallel\_Methods.pdf}.

\bibitem{Detra}
Detra (2023).
\textit{Risk Management with Local Least Squares Monte Carlo}.
Technical Note.
\bibitem{Ghodssi}
Ghodssi, Z. (2021).
\textit{Multilevel Monte Carlo Calculation of American Option Prices}.
Source file: \texttt{Ghodssi\_2021\_MLMC\_Valuation.pdf}.

\bibitem{Parareal}
\textit{Parareal Methods for American Options}.
Source file: \texttt{Parareal\_American\_Options.pdf}.

\end{thebibliography}

\end{document}
